{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch \nimport torch.nn as nn\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.distributions.categorical import Categorical\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm, trange\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:57.212628Z","iopub.execute_input":"2022-05-02T03:15:57.212944Z","iopub.status.idle":"2022-05-02T03:15:58.060180Z","shell.execute_reply.started":"2022-05-02T03:15:57.212893Z","shell.execute_reply":"2022-05-02T03:15:58.059227Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"TRAIN_FILE = '/kaggle/input/smiles/smiles_train.txt'\nMODEL_FILE_OUT = f\"/kaggle/working/model-{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.pth\"\nMODEL_FILE_IN = f'/kaggle/input/model1/model-2022_05_02_02_21_14.pth'\nSUBMISSION_FILE = f\"/kaggle/working/submission-{datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.txt\"\nTRAIN_FROM_SCRATCH = False\nSOS = 'A'\nEOS = 'Z'\nSEED = 2022 \nTEST_SIZE = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:58.065867Z","iopub.execute_input":"2022-05-02T03:15:58.066401Z","iopub.status.idle":"2022-05-02T03:15:58.072794Z","shell.execute_reply.started":"2022-05-02T03:15:58.066361Z","shell.execute_reply":"2022-05-02T03:15:58.071778Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:58.074155Z","iopub.execute_input":"2022-05-02T03:15:58.074521Z","iopub.status.idle":"2022-05-02T03:15:58.083568Z","shell.execute_reply.started":"2022-05-02T03:15:58.074482Z","shell.execute_reply":"2022-05-02T03:15:58.082792Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Exploration","metadata":{}},{"cell_type":"code","source":"with open(TRAIN_FILE) as f:\n    smiles = f.readlines()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:58.085819Z","iopub.execute_input":"2022-05-02T03:15:58.086544Z","iopub.status.idle":"2022-05-02T03:15:58.330912Z","shell.execute_reply.started":"2022-05-02T03:15:58.086494Z","shell.execute_reply":"2022-05-02T03:15:58.330110Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# first visual inspection\nprint(smiles[:30])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:58.333089Z","iopub.execute_input":"2022-05-02T03:15:58.333656Z","iopub.status.idle":"2022-05-02T03:15:58.339594Z","shell.execute_reply.started":"2022-05-02T03:15:58.333614Z","shell.execute_reply":"2022-05-02T03:15:58.338731Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# number of training samples\nprint(f'Number of smiles strings ... {len(smiles)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:58.341134Z","iopub.execute_input":"2022-05-02T03:15:58.341427Z","iopub.status.idle":"2022-05-02T03:15:58.349287Z","shell.execute_reply.started":"2022-05-02T03:15:58.341388Z","shell.execute_reply":"2022-05-02T03:15:58.348311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# distribution of smiles strings lengths\nsmiles_lengths = [len(s) for s in smiles]\nplt.hist(smiles_lengths)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:15:58.351133Z","iopub.execute_input":"2022-05-02T03:15:58.351425Z","iopub.status.idle":"2022-05-02T03:16:03.295856Z","shell.execute_reply.started":"2022-05-02T03:15:58.351389Z","shell.execute_reply":"2022-05-02T03:16:03.295108Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# does every smiles string end with \\n\nsum('\\n' not in s for s in smiles)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:03.297095Z","iopub.execute_input":"2022-05-02T03:16:03.297412Z","iopub.status.idle":"2022-05-02T03:16:03.390888Z","shell.execute_reply.started":"2022-05-02T03:16:03.297364Z","shell.execute_reply":"2022-05-02T03:16:03.390061Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_alphabet(string_list, add_eos=False, add_sos=False):\n    chars = set(''.join(string_list))\n    chars = sorted(chars)\n    if add_eos:\n        chars = [c if c!='\\n' else EOS for c in chars]\n    if add_sos:\n        chars = [SOS] + chars\n    return chars\n\nalphabet = get_alphabet(smiles)\nprint(alphabet)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:03.391964Z","iopub.execute_input":"2022-05-02T03:16:03.392223Z","iopub.status.idle":"2022-05-02T03:16:03.843281Z","shell.execute_reply.started":"2022-05-02T03:16:03.392184Z","shell.execute_reply":"2022-05-02T03:16:03.842450Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Preparation","metadata":{}},{"cell_type":"code","source":"alphabet = get_alphabet(smiles, add_eos=True, add_sos=True)\nprint(alphabet)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:03.844503Z","iopub.execute_input":"2022-05-02T03:16:03.846339Z","iopub.status.idle":"2022-05-02T03:16:04.302939Z","shell.execute_reply.started":"2022-05-02T03:16:03.846297Z","shell.execute_reply":"2022-05-02T03:16:04.301845Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def prepare_smiles(smiles, sos_token, eos_token):\n    return ''.join([sos_token, smiles.replace('\\n', eos_token)])\n\nsmiles_eos = [prepare_smiles(s, SOS, EOS) for s in smiles]\nprint(smiles_eos[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:04.304659Z","iopub.execute_input":"2022-05-02T03:16:04.304935Z","iopub.status.idle":"2022-05-02T03:16:04.877792Z","shell.execute_reply.started":"2022-05-02T03:16:04.304895Z","shell.execute_reply":"2022-05-02T03:16:04.876944Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"smiles_train, smiles_val = train_test_split(smiles_eos, test_size=TEST_SIZE, random_state=SEED)\nprint(f'Training set size ... {len(smiles_train)}')\nprint(f'Validation set size ... {len(smiles_val)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:04.879158Z","iopub.execute_input":"2022-05-02T03:16:04.879449Z","iopub.status.idle":"2022-05-02T03:16:05.245788Z","shell.execute_reply.started":"2022-05-02T03:16:04.879410Z","shell.execute_reply":"2022-05-02T03:16:05.244939Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Encoder:\n    def __init__(self, alphabet):\n        self.alphabet = alphabet\n\n    def smiles2indices(self, smiles):\n        smiles = [s for s in smiles if s in self.alphabet]\n        indices = [self.alphabet.index(s) for s in smiles]\n        return indices\n    \n    def indices2smiles(self, indices):\n        indices = [i for i in indices if i < len(self.alphabet)]\n        smiles = [self.alphabet[i] for i in indices]\n        return ''.join(smiles)\n\n    def __call__(self, x):\n        return self.smiles2indices(x) if type(x) is str else self.indices2smiles(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.249735Z","iopub.execute_input":"2022-05-02T03:16:05.249976Z","iopub.status.idle":"2022-05-02T03:16:05.321369Z","shell.execute_reply.started":"2022-05-02T03:16:05.249943Z","shell.execute_reply":"2022-05-02T03:16:05.320410Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class SmilesDataset(Dataset):\n    def __init__(self, smiles, encoder):\n        super().__init__()\n        self.smiles = smiles\n        self.encoder = encoder\n\n    def __len__(self):\n        return len(self.smiles)\n\n    def __getitem__(self, idx):\n        x = self.encoder.smiles2indices(self.smiles[idx])\n        t = len(x)\n        return x, t","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.322649Z","iopub.execute_input":"2022-05-02T03:16:05.327120Z","iopub.status.idle":"2022-05-02T03:16:05.333608Z","shell.execute_reply.started":"2022-05-02T03:16:05.327076Z","shell.execute_reply":"2022-05-02T03:16:05.332791Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class BidirectionalSmilesCollate:\n    def __call__(self, batch):\n        lengths = [t for (x, t) in batch]\n        max_length = max(lengths)\n        x_for = [np.pad(x, (0, max_length-t), constant_values=EOS_IND) for (x, t) in batch]\n        x_rev = [np.pad(list(reversed(x)), (max_length-t, 0), constant_values=SOS_IND) for (x, t) in batch]\n        t = [t for (x, t) in batch]\n        return (\n            torch.tensor(x_for, dtype=torch.long),\n            torch.tensor(x_rev, dtype=torch.long),\n            torch.tensor(t, dtype=torch.long)\n        )","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.334649Z","iopub.execute_input":"2022-05-02T03:16:05.334902Z","iopub.status.idle":"2022-05-02T03:16:05.344291Z","shell.execute_reply.started":"2022-05-02T03:16:05.334863Z","shell.execute_reply":"2022-05-02T03:16:05.343422Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self, alphabet_size, embedding_dim):\n        super().__init__()\n        self.alphabet_size = alphabet_size\n        self.embedding_dim = embedding_dim\n        self.embedding = nn.Embedding(alphabet_size, embedding_dim)\n\n    def forward(self, x):\n        embedding = self.embedding(x)\n        return embedding","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.345624Z","iopub.execute_input":"2022-05-02T03:16:05.346389Z","iopub.status.idle":"2022-05-02T03:16:05.353315Z","shell.execute_reply.started":"2022-05-02T03:16:05.346348Z","shell.execute_reply":"2022-05-02T03:16:05.352502Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class EncoderLSTM(nn.Module):\n    def __init__(self, embedding, hidden_dim, latent_dim):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.latent_dim = latent_dim\n        self.embedding = embedding\n        self.forward_lstm = nn.LSTM(embedding.embedding_dim, hidden_dim, batch_first=True)\n        self.reverse_lstm = nn.LSTM(embedding.embedding_dim, hidden_dim, batch_first=True)\n        self.mu = nn.Linear(2*hidden_dim, latent_dim)\n        self.log_var = nn.Linear(2*hidden_dim, latent_dim)\n\n    def forward(self, x_for, x_rev, t):\n        embeddings_for = self.embedding(x_for)\n        embeddings_rev = self.embedding(x_rev)\n        outputs_for, (h_l_for, c_l_for) = self.forward_lstm(embeddings_for)\n        outputs_rev, (h_l_rev, c_l_rev) = self.reverse_lstm(embeddings_rev)\n        features_for = torch.gather(outputs_for, dim=1, index=(t-1).reshape(-1, 1).unsqueeze(-1).repeat_interleave(self.hidden_dim, dim=2)).squeeze(dim=1)\n        features_rev = torch.gather(outputs_rev, dim=1, index=(t-1).reshape(-1, 1).unsqueeze(-1).repeat_interleave(self.hidden_dim, dim=2)).squeeze(dim=1)\n        features = torch.cat((features_for, features_rev), dim=1)\n        mu = self.mu(features)\n        log_var = self.log_var(features)\n        return mu, log_var","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.354912Z","iopub.execute_input":"2022-05-02T03:16:05.355551Z","iopub.status.idle":"2022-05-02T03:16:05.368154Z","shell.execute_reply.started":"2022-05-02T03:16:05.355513Z","shell.execute_reply":"2022-05-02T03:16:05.367453Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class DecoderLSTM(nn.Module):\n    def __init__(self, embedding, hidden_dim, latent_dim):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.embedding = embedding\n        self.alphabet_size = embedding.alphabet_size\n        self.lstm = nn.LSTM(embedding.embedding_dim + latent_dim, hidden_dim, batch_first=True)\n        self.linear = nn.Linear(hidden_dim, self.alphabet_size)\n\n    def forward(self, latent_code, last_token, hidden, cell):\n        embedding = self.embedding(last_token)\n        input = torch.cat((embedding, latent_code), dim=1).unsqueeze(dim=1)\n        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n        logits = self.linear(output).squeeze(dim=1)\n        return logits, hidden, cell\n\n    def init_hidden(self, N):\n        last_token = SOS_IND * torch.ones(N).long()\n        last_hidden = torch.zeros((1, N, self.hidden_dim))\n        last_cell = torch.zeros((1, N, self.hidden_dim))\n        return last_token, last_hidden, last_cell","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.369079Z","iopub.execute_input":"2022-05-02T03:16:05.372981Z","iopub.status.idle":"2022-05-02T03:16:05.381715Z","shell.execute_reply.started":"2022-05-02T03:16:05.372921Z","shell.execute_reply":"2022-05-02T03:16:05.380689Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class LSTMVAE(nn.Module):\n    def __init__(self, alphabet_size, embedding_dim, hidden_dim, latent_dim, beta):\n        super().__init__()\n        self.alphabet_size = alphabet_size\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.latent_dim = latent_dim\n        self.beta = beta\n        self.embedding = Embedding(alphabet_size, embedding_dim)\n        self.encoder = EncoderLSTM(self.embedding, hidden_dim, latent_dim)\n        self.decoder = DecoderLSTM(self.embedding, hidden_dim, latent_dim)\n\n    def forward(self, x):\n        pass\n\n    def encode(self, x_for, x_rev, t):\n        mu, log_var =  self.encoder(x_for, x_rev, t)\n        std = torch.exp(log_var / 2)\n        z = self.draw_z(mu, std)\n        return z, mu, log_var\n\n    @torch.no_grad()\n    def decode(self, z, max_length, random=False):\n        results = torch.zeros((z.shape[0], max_length))\n        last_token, last_hidden, last_cell = self.decoder.init_hidden(z.shape[0])\n        for i in range(max_length):\n            logits, last_hidden, last_cell = self.decoder(z, last_token, last_hidden, last_cell)\n            if random:\n                dist = Categorical(logits=logits)\n                last_token = dist.sample()\n            else:\n                last_token = torch.argmax(logits, dim=1)\n            results[:, i] = last_token\n        return results\n\n    def draw_z(self, mu, std):\n        q = torch.distributions.Normal(mu, std)\n        return q.rsample()\n\n    def kl_divergence(self, mu, log_var):\n        kl_divs = -1 * torch.sum(1 + log_var - mu**2 - log_var.exp()) / 2\n        return kl_divs.mean()\n\n    def neg_elbo(self, x_for, x_rev, t, metric):\n        z, mu, log_var = self.encode(x_for, x_rev, t)\n        last_token, last_hidden, last_cell = self.decoder.init_hidden(x_for.shape[0])\n        last_token, last_hidden, last_cell = last_token.to(self.device), last_hidden.to(self.device), last_cell.to(self.device)\n        # init neg_elbo\n        neg_elbo = 0\n        # reconstruction loss\n        for i in range(t.max()):\n            logits, last_hidden, last_cell = self.decoder(z, last_token, last_hidden, last_cell)\n            targets = x_for[:, i]\n            neg_elbo += metric(logits, targets) * (i<t).long()\n            last_token = targets\n        neg_elbo /= t\n        neg_elbo = neg_elbo.mean()\n        # kl-divergence\n        neg_elbo += self.beta * self.kl_divergence(mu, log_var)\n        return neg_elbo\n    \n    @property\n    def device(self):\n        return next(lstm_vae.parameters()).device","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.383450Z","iopub.execute_input":"2022-05-02T03:16:05.383837Z","iopub.status.idle":"2022-05-02T03:16:05.402040Z","shell.execute_reply.started":"2022-05-02T03:16:05.383762Z","shell.execute_reply":"2022-05-02T03:16:05.401289Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"@torch.enable_grad()\ndef train(model, dataloader, metric, optimizer, max_batches=100000, verbose=1000):\n    errors = []\n    model.train()\n    device = model.device\n    for i, (x_for, x_rev, t) in enumerate(tqdm(dataloader)):\n        x_for, x_rev, t = x_for.to(device), x_rev.to(device), t.to(device)\n        loss = model.neg_elbo(x_for, x_rev, t, metric)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        errors.append(loss.item())\n        if i%verbose==0 and i>0:\n            print(f'Training Loss ... {np.mean(errors[-verbose:])}')\n        if i==max_batches-1: break\n    return errors\n\n@torch.no_grad()\ndef validate(model, dataloader, metric, max_batches=100000):\n    errors = []\n    model.eval()\n    device = model.device\n    for i, (x_for, x_rev, t) in enumerate(tqdm(dataloader)):\n        x_for, x_rev, t = x_for.to(device), x_rev.to(device), t.to(device)\n        loss = model.neg_elbo(x_for, x_rev, t, metric)\n        errors.append(loss.item())\n        if i==max_batches-1: break\n    return errors","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.403628Z","iopub.execute_input":"2022-05-02T03:16:05.404153Z","iopub.status.idle":"2022-05-02T03:16:05.416768Z","shell.execute_reply.started":"2022-05-02T03:16:05.404113Z","shell.execute_reply":"2022-05-02T03:16:05.416043Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# optimization hyperparameters\nepochs = 10\nbatch_size = 256\nshuffle = True\nlearning_rate = 0.001\nstep_size = 5\ngamma = 0.1\nmax_batches = 5000\nverbose = 1000\n\n# model hyperparameters\nembedding_dim = 8\nhidden_dim = 128\nlatent_dim = 64\nbeta = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.418062Z","iopub.execute_input":"2022-05-02T03:16:05.418721Z","iopub.status.idle":"2022-05-02T03:16:05.428995Z","shell.execute_reply.started":"2022-05-02T03:16:05.418681Z","shell.execute_reply":"2022-05-02T03:16:05.428198Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"alphabet = get_alphabet(smiles, add_eos=True, add_sos=True)\nalphabet_size = len(alphabet)\n\nencoder = Encoder(alphabet)\nSOS_IND = encoder(SOS)[0] \nEOS_IND = encoder(EOS)[0]\n\ntrain_dataset = SmilesDataset(smiles_train, encoder) \nval_dataset = SmilesDataset(smiles_val, encoder)\ntrain_dataloader = DataLoader(train_dataset, batch_size, shuffle, collate_fn=BidirectionalSmilesCollate())\nval_dataloader = DataLoader(val_dataset, batch_size, collate_fn=BidirectionalSmilesCollate())\n\nlstm_vae = LSTMVAE(alphabet_size, embedding_dim, hidden_dim, latent_dim, beta)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nlstm_vae.to(device)\noptimizer = Adam(lstm_vae.parameters(), learning_rate)\nscheduler = StepLR(optimizer, step_size, gamma)\nmetric = nn.CrossEntropyLoss(reduction='none')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:05.432151Z","iopub.execute_input":"2022-05-02T03:16:05.433018Z","iopub.status.idle":"2022-05-02T03:16:07.846090Z","shell.execute_reply.started":"2022-05-02T03:16:05.432979Z","shell.execute_reply":"2022-05-02T03:16:07.845292Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_errors = []\nval_errors = validate(lstm_vae, val_dataloader, metric)\n\nprint(f'Initial Validation Loss ... {np.mean(val_errors)}')\nplt.plot(range(len(val_errors)), val_errors)\nplt.title('Validation Errors')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:07.847668Z","iopub.execute_input":"2022-05-02T03:16:07.847920Z","iopub.status.idle":"2022-05-02T03:16:43.953695Z","shell.execute_reply.started":"2022-05-02T03:16:07.847885Z","shell.execute_reply":"2022-05-02T03:16:43.952959Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"if TRAIN_FROM_SCRATCH:\n    \n    for e in range(epochs):\n        terrors = train(lstm_vae, train_dataloader, metric, optimizer, max_batches, verbose)\n        train_errors.extend(terrors)\n        print(f'Epoch {e} ... Train Loss {np.mean(terrors)}')\n\n        verrors = validate(lstm_vae, val_dataloader, metric)\n        val_errors.extend(verrors)\n        print(f'Epoch {e} ... Validation Loss {np.mean(verrors)}')\n\n        scheduler.step()\n\n        plt.figure(1)\n        plt.subplot(121)\n        plt.plot(range(len(train_errors)), train_errors)\n        plt.title('Training Errors')\n        plt.subplot(122)\n        plt.plot(range(len(val_errors)), val_errors)\n        plt.title('Validation Errors')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:43.955287Z","iopub.execute_input":"2022-05-02T03:16:43.955730Z","iopub.status.idle":"2022-05-02T03:16:43.963449Z","shell.execute_reply.started":"2022-05-02T03:16:43.955691Z","shell.execute_reply":"2022-05-02T03:16:43.962586Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def save_model(model, model_path):\n    torch.save(model.state_dict(), model_path)\n\ndef load_model(model_path):\n    model = LSTMVAE(alphabet_size, embedding_dim, hidden_dim, latent_dim, beta)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:43.966487Z","iopub.execute_input":"2022-05-02T03:16:43.966681Z","iopub.status.idle":"2022-05-02T03:16:43.975299Z","shell.execute_reply.started":"2022-05-02T03:16:43.966656Z","shell.execute_reply":"2022-05-02T03:16:43.974401Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"if TRAIN_FROM_SCRATCH:\n    save_model(lstm_vae, MODEL_FILE_OUT)\nelse:\n    lstm_vae = load_model(MODEL_FILE_IN)\n    val_errors = validate(lstm_vae, val_dataloader, metric)\n    print(f'Initial Validation Loss ... {np.mean(val_errors)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:16:43.976500Z","iopub.execute_input":"2022-05-02T03:16:43.976757Z","iopub.status.idle":"2022-05-02T03:19:46.846102Z","shell.execute_reply.started":"2022-05-02T03:16:43.976720Z","shell.execute_reply":"2022-05-02T03:19:46.845406Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"lstm_vae.to(torch.device('cpu'))\n\nwith torch.no_grad():\n    x_for, x_rev, t = next(iter(val_dataloader))\n    z, mu, log_var = lstm_vae.encode(x_for, x_rev, t)\n    reconstructions = lstm_vae.decode(z, max_length=100, random=True).long()\n\nfor i in range(min(8, batch_size)):\n    print(encoder(x_for[i, :].tolist()))\n    print(encoder(reconstructions[i, :].tolist()))\n    print(mu[i, :])\n    print(torch.exp(log_var)[i, :])\n    print(100*'-')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:46.847586Z","iopub.execute_input":"2022-05-02T03:19:46.847841Z","iopub.status.idle":"2022-05-02T03:19:47.323713Z","shell.execute_reply.started":"2022-05-02T03:19:46.847806Z","shell.execute_reply":"2022-05-02T03:19:47.322816Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Generation","metadata":{}},{"cell_type":"code","source":"def clean_smiles(smiles):\n    smiles = smiles.replace('A', '')\n    if 'Z' in smiles:\n        first_eos = smiles.index('Z')\n        smiles = smiles[:first_eos]\n    return smiles","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:47.325184Z","iopub.execute_input":"2022-05-02T03:19:47.325444Z","iopub.status.idle":"2022-05-02T03:19:47.329858Z","shell.execute_reply.started":"2022-05-02T03:19:47.325408Z","shell.execute_reply":"2022-05-02T03:19:47.329148Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def generate_smiles(model, n_samples, max_length, random=True):\n    generated_smiles = []\n    with torch.no_grad():\n        Z = torch.randn(n_samples, latent_dim)\n        results = model.decode(Z, max_length, random)\n        for i in range(n_samples):\n            indices = results[i, :].long().tolist()\n            smiles = encoder(indices)\n            smiles = clean_smiles(smiles)\n            generated_smiles.append(smiles)\n    return generated_smiles","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:47.331239Z","iopub.execute_input":"2022-05-02T03:19:47.331697Z","iopub.status.idle":"2022-05-02T03:19:47.342008Z","shell.execute_reply.started":"2022-05-02T03:19:47.331656Z","shell.execute_reply":"2022-05-02T03:19:47.340957Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def write_output(smiles, out_file):\n    smiles = [s+'\\n' for s in smiles]\n    with open(out_file, 'w') as f:\n        f.writelines(smiles)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:47.343269Z","iopub.execute_input":"2022-05-02T03:19:47.343569Z","iopub.status.idle":"2022-05-02T03:19:47.352325Z","shell.execute_reply.started":"2022-05-02T03:19:47.343535Z","shell.execute_reply":"2022-05-02T03:19:47.351347Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"n_samples = 100\ntimes = 100\nmax_length = 110\nrandom = True","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:47.353969Z","iopub.execute_input":"2022-05-02T03:19:47.354515Z","iopub.status.idle":"2022-05-02T03:19:47.361612Z","shell.execute_reply.started":"2022-05-02T03:19:47.354477Z","shell.execute_reply":"2022-05-02T03:19:47.360708Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"generated_smiles = []\nfor _ in trange(times):\n    new_smiles = generate_smiles(lstm_vae, n_samples, max_length, random)\n    generated_smiles.extend(new_smiles)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:47.362929Z","iopub.execute_input":"2022-05-02T03:19:47.363665Z","iopub.status.idle":"2022-05-02T03:19:57.406210Z","shell.execute_reply.started":"2022-05-02T03:19:47.363625Z","shell.execute_reply":"2022-05-02T03:19:57.405448Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"generated_smiles[:10]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:57.407775Z","iopub.execute_input":"2022-05-02T03:19:57.408046Z","iopub.status.idle":"2022-05-02T03:19:57.413959Z","shell.execute_reply.started":"2022-05-02T03:19:57.408007Z","shell.execute_reply":"2022-05-02T03:19:57.413204Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"write_output(generated_smiles, SUBMISSION_FILE)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T03:19:57.415224Z","iopub.execute_input":"2022-05-02T03:19:57.415636Z","iopub.status.idle":"2022-05-02T03:19:57.429804Z","shell.execute_reply.started":"2022-05-02T03:19:57.415594Z","shell.execute_reply":"2022-05-02T03:19:57.429044Z"},"trusted":true},"execution_count":34,"outputs":[]}]}